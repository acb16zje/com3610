\documentclass[12pt, a4paper]{report}
\edef\restoreparindent{\parindent=\the\parindent\relax}
\usepackage[UKenglish]{babel}
\usepackage[bibstyle=ieee, dashed=false, sorting=nty]{biblatex}
\usepackage[labelfont=bf]{caption}
\usepackage{colortbl}
\usepackage{csquotes}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage{graphicx}
\usepackage[hidelinks]{hyperref}
\usepackage{microtype}
\usepackage{parskip}
\usepackage{pgfgantt}
\usepackage{subcaption}

\linespread{1.2}
\restoreparindent

\pagestyle{fancy}
\fancyhf{}
\fancyhead[C]{\leftmark}
\fancyfoot[C]{\thepage}

\addbibresource{references.bib}

\begin{document}
\begin{titlepage}
	\centering
	\includegraphics[width=10cm]{images/tuos_logo}\par\vspace{1cm}
	\vspace{1cm}

	{\huge\bfseries Finding Security Issues in (Open Source) Software Repositories\par}
	\vspace{1cm}

	{\Large Zer Jun Eng\par}
	\vspace{1cm}

	supervised by\par Dr.~Achim \textsc{Brucker}
	\vfill

	{This report is submitted in partial fulfilment of the requirement for the degree of MEng Software
		Enginnering by Zer Jun Eng}
	\vfill

	{\large COM3610}
	\vfill

	{\large \today}
\end{titlepage}

\pagenumbering{roman}

\chapter*{Declaration}
All sentences or passages quoted in this report from other people's work have been specifically
acknowledged by clear cross-referencing to author, work and page(s). Any illustrations that are not
the work of the author of this report have been used with the explicit permission of the originator
and are specifically acknowledged. I understand that failure to do this amounts to plagiarism and
will be considered grounds for failure in this project and the degree examination as a whole.
\vspace{2cm}

\noindent \begin{tabular}{llp{4.5cm}}
	Name & : & Zer Jun Eng \\ \cline{3-3}
	\\ [-0.5em]
	Date & : & \today      \\ \cline{3-3}
\end{tabular}

\newpage

\chapter*{Abstract}
In both proprietary and Free/Libre and Open Source Softwares (FLOSS) components, not all security
vulnerabilities are documented in CVE format nor published in the vulnerability databases such as
NVD. These vulnerabilities could have been fixed by the developers. Finding these
vulnerability-fixing commits could provide valuable insights for the developers using those
components. Therefore, the objective of this project is to develop a repository mining tool that is
able to detect vulnerability-fixing commits using MSR approach. Comparing to previous approaches,
the tool will be focusing on searches the commit message first, and then investigates the code
difference in each commit.

\chapter*{Acknowledgements}
I would like to thank my parents for their unconditional love and the full financial support
throughout my university life. It would not be possible for me to finish this project and my course
without them.

I would also like to thank my supervisor, Dr. Achim Brucker for continuously providing constructive
advice for my project. I am honoured to work with you, and I look forward to working with you in the
future.

\newpage

\tableofcontents

\listoffigures

\listoftables

\newpage

\pagenumbering{arabic}

\chapter{Introduction}
\section{Background}
Free/Libre and Open Source Software (\textbf{FLOSS}) is a type of software whose license allows the
users to inspect, use, modify and redistribute the software's source code \cite{crowston_2012}.
Since the introduction of the version control system, many repository hosting sites such as
SourceForge \cite{sourceforge}, Google Code \cite{google_code}, and GitHub \cite{github} have been
launched. As a result, the participation of global communities into FLOSS projects have started to
grow and different contributions were made to improve the softwares quality, which included fixing
software vulnerabilities \cite{dabbish_2012}.

Building a secure software is expensive, difficult, and time-consuming. It is necessary to know when
and how a security vulnerability is fixed throughout the software lifecycle. Software components
such as plugins and application processing interfaces (\textbf{APIs}) are usually developed by
third-party developers and widely reused in both open source and closed source softwares
\cite{khan_2001}. An important factor of the software security is determined by the information
provided by the vendor of the software components for deciding whether to perform the security
update. Hence, the users of software components are advised to check the National Vulnerability
Database (\textbf{NVD}) \cite{nvd} regularly for detailed information of the vulnerabilities
identified in the software components used. Furthermore, it would be more helpful if the developers
of the software components clearly record the list of changes or provide informative Git commit
messages for every version update of their component.

To perform a risk assessment of a potentially vulnerable component, it is required to have a deep
understanding of the vulnerability entry points. However, not all projects follow the CVE format or
publish CVEs, and CVE reports are usually lack of technical details that attribute the specific
entry points of the vulnerability, which is an important aspect in part of the risk assessment. By
identifying the vulnerability-fixing commits, the vulnerable lines of code can be located, which
allows the users to check if a vulnerable component is being used or not. However, some developers
believe that public disclosure of security vulnerabilities patch is dangerous, thus
vulnerability-fixing commits are not commonly identified and recorded specifically in some open
source software repositories to prevent malicious exploits \cite{arora_2005}. As a result, there is
a practical difficulty in applying this analysis approach to find the security relevant commits that
are not documented using CVE or a similar format, which are known as the silent patches.

To address these issues, a repository mining tool that investigates commit messages and identifies
vulnerable software components can be developed to reduce the time and cost required to mitigate the
vulnerabilities. The repository mining tool should be able to detect the silent patches through an
advanced process, which the tool must analyse the source code changes between commits to locate the
vulnerable lines of code. Moreover, the mining tool should be applicable to all types of software
projects that are using Git as their version control system. Projects that are using a different
version control system are also supported after they have been migrated to Git.

\section{Objectives} \label{sec:objectives}
\begin{itemize}
	\item Identify the security patterns of the most popular security issues in OWASP Top Ten Project.
	\item Develop a repository mining tool to search through the commit history of a repository and
	find a list of commit messages that match the patterns. The list should be produced in a suitable
	file format such as JSON, XML, or CSV.
	\item Extend the mining tool which checks the code difference in the commits found to obtain the
	actual commits fixing the security vulnerabilities. This extension should separate from the mining
	process to make the mining results easier to verify and debug.
\end{itemize}

\section{Challenges} \label{sec:challenges}
This section is a brief summary of the main challenges that might occurred during the project. A
more thorough analysis of the problems and constraints is carried out in
\hyperref[sec:problems_and_constraints]{\textbf{Section 3.5}}.

\begin{itemize}
	\item \textbf{Data}: There are a large number of open source repositories available on GitHub.
	However, it is challenging to find a set of sample repositories that can produce accurate and
	consistent results.
	\item \textbf{Misclassification}: The commit messages for the same vulnerability patch are not
	always the same, thus misclassification is inevitable. Using regular expressions to match the
	patterns in the mining process do not guarantee the correctness of the result.
	\item \textbf{Evaluation}: After mining a list of commits that contain the identified patterns in
	its message, the evaluation process might not correctly locate the lines of code that addressed
	the security vulnerability. It might be required to perform a manual evaluation to correctly
	identify some of the results.
	\item \textbf{Time}: Large repository such as Linux which has more than 780,000 commits in total
	\cite{linux_repo} could be extremely time-consuming for the repository mining tool to complete the
	search and evaluation process.
\end{itemize}

\section{Report Structure}
\textbf{Chapter 2} reviews a range of academic articles, theories, and previous studies that is
related to this project, as well as investigating the techniques and tools to be used.

\noindent\textbf{Chapter 3} is a list of detailed requirements and a thorough analysis of design,
implementation and testing stage. Some core decisions are reviewed in the analysis part to ensure
the feasibility of the project.

\noindent\textbf{Chapter 4} is a comparison between different design concepts, where the advantages
and disadvantages of different approaches are stated. The chosen design is justified with suitable
diagrams provided including wireframes and UML component diagrams.

\noindent\textbf{Chapter 5} describes the implementation process by highlighting novel aspects to
the algorithms used. Testing is performed by following a suitable model to evaluate the
implementation.

\noindent\textbf{Chapter 6} presents all the results along with critical discussions about the main
findings,	and outlines the possible improvements that could be made in the future work.

\noindent\textbf{Chapter 7} summarises the main points of previous chapters and emphasise the
results found.

\section{Relationship to Degree Programme}
This project focuses on the research of real-world software security problems and offers valuable
insights into computer security. By studying the patterns of security vulnerabilities patch in open
source repositories, the practical knowledge for building and ensuring a secure system could be
gained. Moreover, the difficulty of improving software security could be experienced during the
evaluation process in this project. This relates to the Software Engineering degree as it requires a
good understanding in version control system and it aims to improve softwares quality by reducing
the time and effort needed to find security vulnerabilities in the source code.

\chapter{Literature Review}
This chapter will start with the background contents of the project, and then focus on discussing
the security aspect of open source softwares. Additionally, previous and existing relevant works are
reviewed and a critical analysis is provided for the comparison of these resources and this project.

\section{Open Source Security}
The security of open source softwares mostly rely on the collaboration of the community. It is
deduced that the power of open data and crowdsourcing will make open source security more reliable
\cite{hoepman_2007, witten_2001}, and provides more flexibility and freedom over the security option
to their users \cite{payne_2002}. However, when it comes to publishing the vulnerability
information, it is suggested that the list of unconfirmed vulnerabilities should not be published
publicly to protect the users from potential harms \cite{schryen_2011}.

Arora, Nandkumar and Telang \cite{arora_2006} have shown that vulnerabilities that are either secret
or published but not patched attract fewer attacks than patched vulnerabilities. Although the
research was conducted in 2006 and the results might be outdated, it still implies that developers
might include a silent patch into some of the commits that is not explicitly recorded in the commit
messages. It might be a rational approach for not disclosing the work attempted to fix a
vulnerability, but other developers might not be informed of the content change. Furthermore, if a
similar vulnerability is discovered in the future, developers would need more effort for finding the
previous solution. Therefore, it would be very useful for the developers if the mining tool
developed in this project could detect the silent patches.

\section{Taxonomy of Software Vulnerabilities}
There are many software vulnerabilities being identified each year. By using a common vulnerability
identifier system, vulnerability data can be shared across separate vulnerability databases to
facilitate the interoperability of different tools. As this project focuses on finding security
issues in open source repositories, it is necessary to discuss the industry-endorsed standard of
software vulnerabilities categorisation.

\subsection{Common Weakness Enumeration}
The Common Weakness Enumeration (\textbf{CWE}) is a project launched by the Mitre Corporation and
sponsored by the National Cyber Security Division of the United States Department of Homeland
Security \cite{cwe}. The CWE project organises the software weaknesses into a list of different
categories, known as the CWE list. Software weaknesses are defined as errors that can lead to
software vulnerabilities, which includes buffer overflows, authentication errors, code injection,
etc. \cite{cwe_faq}. The CWE is now a formal standard for representing software weaknesses. Each
entry in the CWE list contains detailed information about the specific weakness and is identified by
a unique ID number.

\subsection{Common Vulnerabilities and Exposures}
The Common Vulnerabilities and Exposures (\textbf{CVE}) is another security project launched by the
Mitre Corporation \cite{cve} to provide the community with a complete list of publicly known
security vulnerabilities, known as the CVE entries. Each CVE entry is defined by an ID number, and
includes a description followed by any relevant resources about the vulnerability. It is now the
standardised solution and industry-recognised standard for identifying vulnerabilities and
exposures. However, developers and vendors are not required to publish security vulnerabilities of
their projects in CVE format. They are allowed to use their own naming scheme for the
vulnerabilities, even if the same vulnerability has already been recorded in the CVE list.

\section{Security Issues in Open Source Softwares}
The Open Web Application Security Project (\textbf{OWASP}) is a worldwide non-profit organization
committed to improve and raise the awareness of software security \cite{owasp_home}. The project
members of OWASP have worked together to produce a list of the most critical web application
security risks based on the community feedback and comprehensive data contributed by different
organizations. The list consists of ten categories of security attacks which are considered to be
the most dangerous and popular in recent years. In OWASP Top Ten 2017 \cite{owasp_top10}, one of the
vulnerabilities that is closely related to this project is \textit{Using Components with Known
Vulnerabilities}, which will be extensively discussed.

\subsection{Using Components with Known Vulnerabilities} \label{subsec:components}
It has been indicated that a small software component could create a large error in a software
system \cite{basili_1984, munson_1992, selby_1988}. Components such as plugins, libraries, and
modules are ubiquitous in both open source and proprietary softwares. Third-party components are
increasingly being integrated into softwares to reduce the amount of time and effort required for
development \cite{balzarotti_2006}, but they also increase the risk of vulnerabilities being
introduced into the softwares. These components are mostly maintained by different developers or
organisations, and the time required to fix a vulnerability varies between developers. While the
majority of third-party components are still being actively maintained after a long time, some of
them might have depreciated and security patches are no longer being released. The users might
continue to use a depreciated component if they could not find a better alternative. However, using
outdated components greatly increase the risk of software exploits. Therefore, for any large-scale
system, the developers must scan for vulnerabilities regularly and subscribe to the security news
related to the components used to reduce the risk of security vulnerabilities being introduced into
the system.

Vulnerable components can be found using methods ranging from dependency checking to machine
learning. While this project is related to the former approach, the latter approach concentrates on
finding the relationship between software errors and vulnerabilities to identify or predict
high-risk components. Dependency checking is an approach of detecting dependencies (plugins,
libraries, etc.) with known vulnerabilities in a software. Several open source tools including OWASP
Dependency Check \cite{owasp_dependency}, Retire.js \cite{retirejs}, and Safety \cite{safety} are
applications that identifies vulnerable dependencies in a software project. Cadariu et al.
\cite{cadariu_2015} have used the OWASP Dependency Check tool to find all known vulnerabilities that
have a unique CVE identifier in proprietary softwares written in Java. According to their study, the
OWASP Dependency Check tool has low precision due to the high false positives rate in the large data
sets. However, Cadariu et al. justified that the tool is still usable by taking into account that
the checking process is automated and any security issue found is considered a valuable information
for the users.

Machine learning-based approaches are also applicable to find vulnerable components in a software
system. Briand, Basili and Hetmanski \cite{briand_1993} have developed a model with Optimised Set
Reduction (OSR) algorithm that uses set theory, predicate logic, probability, and vector in the
calculation. The model focused on identifying the components that are more likely to produce a large
number of errors and it was proved to be effective, but the main drawbacks are the complexity of the
implementation and the extensive calculations required. In comparison to Briand's approach,
Scandariato et al. \cite{scandariato_2014} have built a model that uses text mining techniques to
predict vulnerable components. While Briand's model is capable of identifying high-risk components,
Scandariato's model is able to predict vulnerabilities in the future releases of a software
components, and the results achieved are satisfactory.

As a conclusion, static dependency checking tools provide a fast and easy way to scan for vulnerable
components, but the users are required to verify the validity and compatibility of the results with
their softwares. In contrast, models that use machine learning technique has been proved to be
effective and are more likely to produce consistent and accurate results. However, such models
require a large amount of training data and are only designed for a specific area. While dependency
checking approach is more related to the scope of this project, the capability of predicting
vulnerable software components through machine learning is a great way of preventing severe software
errors. In future work, machine learning could be incorporated into the tool developed in this
project to improve its overall effectiveness.

\section{Mining Software Repositories}
Mining Software Repositories (\textbf{MSR}) is a process of collecting and analysing data from
repositories, which includes version control repositories, mailing list repositories, and bug
tracking repositories. MSR applies to a wide range of fields such as business, research, and
security \cite{poncin_2011}. The purpose of MSR is to extract practical information from rich
metadata and discover hidden trends about a specific evolutionary characteristic \cite{kagdi_2007}.
The information collected could be used in various development process. For example, some developers
could gain insight by mining repositories, which may help them to enhance their software quality
based on previous implementation evidence of other developers \cite{hassan_2008}. While MSR have
various usages in different areas, the primary objective of this project will be focusing on finding
the security issues in open source software repositories through MSR.

In order to identify both hidden and publicly disclosed patches, it is required to make effective
use of MSR technique. A MSR process is normally carried out using tools or scripts made by the
researchers themselves. Although there are many types of research in the MSR field in recent years,
the majority of the tools or scrips used are not published publicly \cite{robles_2010}. As a result,
it is not possible to fully replicate the previous research methods and make improvements based on
that. Despite the undisclosed information of research methods in many papers, Shang
\cite{shang_2009} suggested that the MSR process should be split into several stages, with each
stage focusing on a specific topic of the problem to achieve the optimal efficiency.

\subsection{Keywords Search}
For many complex approaches, the keywords searching process is considered to be the fundamental
step. If the initial results produced in the searching stage is good, a huge amount of effort could
be reduced in the later stages. However, the prerequisite is that the repository must have a
sufficient amount of valuable information, which can be estimated by judging the history of the
repository. To correctly and precisely retrieve the information for a query, it is required to
integrate some algorithms and modules into the search function. Matsushita, Sasaki, and Inoue
\cite{matsushita_2005} developed a repository search system that makes use of two functions: lexical
analysis function and token comparing function. The system produced very detailed results by
deploying recursive search strategy using the keywords found into every commit. On the contrary,
Mockus and Votta \cite{mockus_2000} designed an automated program that makes use of normalisation,
word frequency analysis, and keyword clustering techniques to search the commit messages. Although
the program is able to retrieve the results that include the keywords, the algorithm is unable to
identify similar terms or inconsistent form of wording for the commit messages.

\subsection{Properties of Vulnerability-Fixing Commits}
For every vulnerability identified in a repository, the vulnerability-fixing process that involves
analysis, implementation, testing, and release will be executed \cite{othmane_2015}. Most of the
vulnerability-fixing commits are pushed during the implementation and testing stage of the process.
However, if the commit message of a fixing commit is ambiguous, it will be challenging for any tools
to determine the correctness of the commit. In order to analyse the common features of the
vulnerability-fixing commits, it is needed to find these commits in open source repositories first.
By analysing the properties of vulnerability-fixing commits, it will ease the implementation of the
repository mining tool and enhance the quality of the regular expressions used.

Meneely et al. \cite{meneely_2013} conducted a research to study the properties of commits that
introduce vulnerabilities, in which a reverse approach was used to find vulnerability-contributing
commit by backtracking from the vulnerability-fixing commits. Meneely et al. identified the
vulnerability-fixing commits by investigating into each vulnerability manually to find the
respective fixing commit. However, the process of identifying vulnerability-fixing commit was not
clearly explained by them, thus no constructive information about the properties of
vulnerability-fixing commits is provided. On the contrary, V{\'a}squez, Bavota and Vel{\'a}squez
\cite{linares_2017} discovered that some vulnerability-fixing commits are grouped with other commits
to address a vulnerability, which matches the assumption of Neuhaus and Plattner
\cite{neuhaus_2013}, and thus only part of the code commited is related to the vulnerability fix.

\begin{figure}[H]
  \centering
  \begin{subfigure}{\textwidth}
    \centering
    \includegraphics{images/vuln_fixing_commit_good_ex.png}
    \subcaption{Vulnerability fix in Linux kernel repository {\cite{good_vfc}} \label{figure:g_vfc}}
  \end{subfigure} \\
  \begin{subfigure}{\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/vuln_fixing_commit_bad_ex.png}
    \subcaption{Vulerability fix in oauth2 proxy repository {\cite{bad_vfc}} \label{figure:bad_vfc}}
  \end{subfigure}
  \caption[Examples of vulnerability-fixing commit]%
  %
  {A comparison of \hyperref[figure:g_vfc]{\textbf{(a)}} a higher quality and
  \hyperref[figure:bad_vfc]{\textbf{(b)}} a lower quality vulnerability-fixing commit.}
  \label{figure:comparion_vfc}
\end{figure}

\subsection{Finding Security Vulnerabilities} \label{subsec:finding_vuln}
It has been reported that the descriptions and references in vulnerability databases are often lack
of complete documentation \cite{massacci_2010}, and vulnerability-fixing commit are not ubiquitous
in every open source repository \cite{walden_2014}. Finding a security vulnerability could be hard
if the resources available are limited. Having completed the researches on keywords searching
techniques and properties of vulnerability-fixing commit, the approach for finding vulnerabilities
can now be reviewed.

In this project, a static repository mining tool will be developed to find security vulnerabilities
in open source repositories. Previous researches included the use of static software auditing and
vulnerability mitigation tools to find bugs and vulnerabilities \cite{cowan_2003}. However, Bessey
et al. \cite{bessey_2010} claimed that static tools have a negative effect on technical development
due to its high false positives rate. While this statement might be true, it does not imply that all
static tools are not effective as they differ in the techniques used in finding vulnerabilities
\cite{moser_2008}. Static tools usually require many experiments with different configurations to
obtain the best result, and the result may vary across different data sets. This project differs
from previous researches by aiming to find the security vulnerabilities through Git commit messages
first, and then analyse the code changes in the commits. Researches have shown that
vulnerability-fixing commits could be retrieved by extracting commit hashes from CVE references and
gathering all commits that refer to a CVE number in its commit message \cite{jimenez_2016}, or by
performing syntactic and semantic analysis on the commit messages \cite{sliwerski_2005}. To verify
the validity of the commits retrieved, a screening test \cite{dashevskyi_2018} can be performed to
investigate the code changes in a commit against several criteria and identify the correct
vulnerability-fixing commits.

This project extends prior work on Reis and Abreu's Secbench Mining Tool \cite{secbench}. The tool
aims to find vulnerabilities patch in GitHub repositories by using specific regular expressions for
each vulnerability pattern. Then it creates a test case for every vulnerability found and these test
cases are evaluated manually. Reis and Abreu \cite{reis_2017} discussed the procedure of the
evaluation and explained that human errors could occur due to source code complexity and similarity
of vulnerability pattern. The approach of Secbench Mining Tool is similar to the concept of this
project. However, performing manual evaluation on every result is not practical and it is proven
that the use of automated algorithms can improve the detection process \cite{livshits_2005}. In this
project, the tool developed should be able to automate the evaluation process to some extent, while
preserving the accuracy of the results.

\subsection{Source Code Analysis}
This section is an extension to \hyperref[subsec:finding_vuln]{\textbf{Section 2.4.3}}. As this
project involves in analysing the code changes in commits, it is necessary to review the techniques
used to identify vulnerabilities by source code analysis.

Finding vulnerabilities by source code analysis technique is relatively difficult than analysing
commit messages as it requires a high-level understanding in both software vulnerabilities and the
programming language of the source code. Source code analysis tools are generally designed for a
specific task, and are only usable for some programming languages \cite{antunes_2009}. One of the
advantages of source code analysis tool is that it can analyse the code without executing it
\cite{livshits_finding_2005}, but this could also be the drawback as it might generate more false
positives than dynamic analysis. Zitser, Lippmann, and Leek \cite{zitser_2004} have developed a
static code analysis tool to find buffer overflow vulnerability in C programming language code.
Their approach requires manual definitions of the overflow pattenrs in their tool, which is
considered to be a general method in static analysis.

\section{Usage of the Repository Mining Tool in Other Areas}
While the repository mining tool developed in this project is only capable of finding security
issues through Git commits, it can be extended or modified to aid the researches in other areas.
Some examples are briefly discussed in the subsections below.

\subsection{Bugs Finding Model}
Both Williams and Hollingsworth \cite{williams_2005} and Ostrand and Weyuker \cite{ostrand_2004}
utilised MSR technique in their bugs finding model. Williams and Hollingsworth mined the code
changes in each commit to find possible bugs, while Ostrand and Weyuker mined the most frequently
modified files between version releases to predict the bugs-prone files.

\subsection{Machine Learning Model for Automated Vulnerability Prediction}
In comparison to the static approach used in the mining tool, machine learning technique could be
introduced to achieve higher reliability and accuracy on the result. Nguyen and Tran
\cite{nguyen_2010} and Perl et al. \cite{perl_2015} have built their machine learning model with
dependency graph and vulnerability-contributing commit as their main approach respectively, while Li
et al. \cite{li_2016} and Russell et al. \cite{russell_2018} used source code analysis method in
their machine learning model. According to their researches, machine learning models are able to
produce relatively high accuracy results.

\chapter{Requirements and Analysis}
The purpose of this chapter is to express the aims in details and discuss the problems to be solved.
This chapter will outline the requirements of the project and list the criteria to be met. The
analysis part will cover every aspect of the design, implementation, and testing stage to ensure
that the project is feasible.

\section{Project Objectives}
Initially, the objectives set in \hyperref[sec:objectives]{\textbf{Section 1.2}} are an ideal
concept of this project. Having completed the background research and literature review, it is now
possible to provide a detailed description and more clearly defined objectives that improve the
feasibility of this project.

\begin{enumerate}
	\item \textbf{Vulnerability patterns}: The term `vulnerability pattern' is used to represent the
  commit message pattern of different vulnerabilities. Correctly identifying the regular expression
  of each vulnerability pattern is time-consuming, and it would also need considerable refinement
  throughout the whole project. Hence, it might be more appropriate to reuse and improve the
  patterns provided in previous related works.
	\item \textbf{Mining the commits}: This task involves creating a repository mining tool that makes
	extensive use of the pre-defined regular expressions to search for the relevant commits. It is
	necessary to consider how closely a commit needs to match with the patterns for it to be included
	in the result. The file format for storing the results is JSON, and reasons are justified in
	\hyperref[subsec:file_format]{\textbf{Section 3.3.3}}.
	\item \textbf{Evaluating the mined commits}: The mining tool can be extended to include a separate
	function that evaluates the commits mined to find the actual code commit addressing the security
	vulnerabilities. This project will consider to automate the evaluation process to some extent
	while maintaining the accuracy of the results at the standard level.
\end{enumerate}

\section{Software Requirements and Scope}
\subsection{Functional Requirements}
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|p{10.3cm}|c|}
			\hline
			\rowcolor[HTML]{D8D8D8}
			\multicolumn{1}{|c|}{Criteria} & Importance \\ \hline
			\textbf{Compatibility}: The mining tool should be able to run on all machines that meet the
			system requirements. & Essential \\ \hline
			\textbf{Completeness}: The mining tool should be able to find all relevant commits of security
			vulnerabilities based on the regular expressions. & Essential \\ \hline
			\textbf{Repeatable}: The results should be repeatable and reproducible. & Essential \\ \hline
			\textbf{Scalability}: The mining tool should be able to work on different project sizes,
			provided that the repository contains a certain amount of information. & Essential \\ \hline
			\textbf{Automated Evaluation}: The process of classifying and evaluating the commits into
      different vulnerabilities patch should be automated to a certain extent. & Desirable \\
			\textbf{Robustness}: The mining tool should be able to handle all possible errors without
			terminating the mining process. & Desirable \\ \hline
    \end{tabular}
    \caption{Functional requirements of the mining tool} \label{table:func_req}
	\end{center}
\end{table}

\subsection{Non-functional Requirements}
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|p{10.3cm}|c|}
			\hline
			\rowcolor[HTML]{D8D8D8}
			\multicolumn{1}{|c|}{Criteria} & Importance \\ \hline
			\textbf{Code Style}: The source code should be well-commented and follow a consistent coding
      style. & Essential \\ \hline
      \textbf{Documentation}: Installation and user manual should be provided. & Essential \\ \hline
      \textbf{Lightweight}: The mining tool should have minimal dependencies. & Essential \\ \hline
      \textbf{Open source}: As the mining tool is built for researching open source repositories, it
      should be open source to suit the use cases. & Essential \\
      \textbf{Performance}: The performance of the mining tool should be optmised for different
      project sizes. & Desirable \\
      \hline
			\end{tabular}
		\caption{Non-functional requirements of the mining tool} \label{table:nonfunc_req}
	\end{center}
\end{table}

\subsection{Scope}
In addition to \hyperref[table:func_req]{\textbf{Table 3.1}} and
\hyperref[table:nonfunc_req]{\textbf{Table 3.2}}, several fundamental requirements can be included
to define the scope of the mining tool.

\begin{itemize}
	\item \textbf{Language in Commit Messages}: The mining tool will only search for commit messages
	that are written in English.
	\item \textbf{Programming Language}: The source code analysis function in the mining tool will
	only support Python 3.
	\item \textbf{Repository type}: The mining tool will only support Git repositories. Hence, other
	version control systems such will have to convert to Git first before using the mining tool.
	\item \textbf{Vulnerability type}: It is aimed that the mining tool should be able to detect
	CVE-identified vulnerabilities that have been fixed and recorded in the commit message
	\hyperref[figure:cve_vuln]{\textbf{Figure 3.1 (a)}}, and vulnerabilities that are not identified
	in CVE but recorded in the commit messages \hyperref[figure:common_vuln]{\textbf{Figure 3.1 (b)}}.
\end{itemize}

\begin{figure}[H]
  \centering
  \begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=.85\linewidth]{images/cve_vuln.png}
    \subcaption{CVE-identified vulnerability fix {\cite{cve_vuln}} \label{figure:cve_vuln}}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=.85\linewidth]{images/common_vuln.png}
    \subcaption{Common vulnerability fix {\cite{common_vuln}} \label{figure:common_vuln}}
  \end{subfigure}
  \caption[Comparison of a CVE-identified and common vulnerability-fixing commit]%
  %
  {An example of \hyperref[figure:cve_vuln]{\textbf{(a)}} a CVE-identified vulnerability fix and
  \hyperref[figure:common_vuln]{\textbf{(b)}} a common vulnerability fix.}
  \label{figure:fig_scope}
\end{figure}

\section{Analysis}
The aim of this section is to contemplate the options available for this project and review some of
the fundamental decisions to be made before the implementation.

\subsection{Programming Language}
Python 3 \cite{python} is chosen to be the main programming language for the repository mining tool.
While other programming languages may be more suitable for tackling specific problems of this
project, Python 3 provides sufficient coverage over every aspect with its comprehensive
functionality. The greatest advantage of Python 3 is that it has a wide range of libraries that
facilitate the development environment, which fully justified that a complete working solution can
be produced using Python 3.

\subsection{Libraries and Tools}
Since the mining tool is decided to be programmed in Python 3, a wide range of libraries could be
integrated to enhance its functionality.
\begin{itemize}
	\item PyGithub is a Python library build to access the GitHub API \cite{pygithub}.
	\item GitPython is a Python library build to interact with Git repositories using a combination of
	python and git command implementation \cite{gitpython}.
\end{itemize}

\subsection{File Format of Result} \label{subsec:file_format}
The JavaScript Object Notation (\textbf{JSON}) \cite{json} has been chosen as the file format for
storing the results in this project. This is because JSON is supported in Python and it does not
require complicated operations in Python to access the data. While various alternative data
interchange formats such as the Extensible Markup Language (\textbf{XML}) \cite{xml} has its unique
advantages, it is important to choose a data interchange format that consumes less resource and have
lower processing time for a large amount of data. Since it has been proved that JSON has better
performance than XML in terms of processing time and resource utilisation \cite{nurseitov_2009}, it
is considered that JSON would be the best option for this project.

\section{Proposed Method}
This project strongly emphasises the need for finding security issues in open source repositories by
mining software repositories. While it might be impossible to discover the security patches in a
repository through a single search, the problem could be solved using divide and conquer. The ideal
concept of this project is to build a command-line interface program that is able to run two
separate processes: the \textbf{mining} process and the \textbf{evaluation} process. The
\textbf{mining} process takes a Git repository as input, searches through the commit log, and stores
the list of commits that might potentially contain a patch in a JSON file. The \textbf{evaluation}
process takes a JSON file as input, and check the code difference of every commit in the log file to
identify the real patches.

\section{Problems and Constraints} \label{sec:problems_and_constraints}
As mentioned in \hyperref[sec:challenges]{\textbf{Section 1.3}}, the main challenges of this project
are \textbf{data}, \textbf{misclassification}, \textbf{evaluation} and \textbf{time}. The subsequent
challenge is the implementation difficulties, which the severity is dependent on the complexity of
the problems and the resources available. It is also expected that some problems might not be solved
and new problems could emerge in the course of the project. This section will discuss the problems
in detail and review several ways of mitigating them, as well as analysing the possible constraints
that might affect the progress of the project.

\subsection{Quality of Commit Messages} \label{subsec:commit_quality}
Although there are a lot of open source repositories available online, the majority of them does not
have a formal guideline for the documenting the changes in the commit messages. As part of the
\textbf{data} problem, the commit messages in the real-world repositories
(\hyperref[sec:realworld]{\textbf{Section 3.7.1}}) might have lower quality compared to a
self-created repository. It has been reported that the terms \textit{fix}, \textit{add}, and
\textit{test} have the top average term frequency in the commit messages \cite{alali_2008}. With
these indistinct terms being widely used in the commit messages, the performance of the tool may
drop on real-world repository test sets and it would require extra effort for finding the relevant
vulnerability-fixing commits.

\subsection{Results Evaluation Process}
It is estimated that the \textbf{evaluation} process would be the biggest challenge of this project
since it was regarded as a complicated and difficult area in previous researches. Moreover, this
project plans to implement an automated version of the evaluation process, which will further
increase the difficulty level. The implementation of automated evaluation is hard and it does not
guarantee to provide a good result. It is also extremely challenging for the mining tool to work
across repositories programmed in different programming languages. The constraint is that the tool
has to be exhaustively tested to find the optimal threshold value and for it to be automated and
produce good results. Although the tool might produce good results on some repositories, it does not
indicate that the tool will produce consistent results on all repositories. To ensure the minimum
quality of the results, one of the solutions might be using both automated method for basic
filtering and a manual method for advance refinement.

\subsection{Code Changes Analysis}
As discussed in \hyperref[subsec:commit_quality]{\textbf{Section 3.5.1}}, the commit messages in
real-world repositories will contain noise and inconsistency that might affect the results
retrieved. Therefore, it is expected that the results will contain a certain amount of false
positive commits. By analysing the code changes of the commits retrieved, the validity of a commit
can be verified by finding the changes for vulnerable lines of code, as shown in
\hyperref[figure:code_diff]{\textbf{Figure 3.2}}.

However, the step of correctly identifying the vulnerable lines of code is challenging as it varies
with different programming languages. Firstly, different programming languages have different code
syntax, and thus the code changes for addressing the same vulnerability might be different across
different programming language. Secondly, the code changes of a commit only represent a small
fragment of the whole source code, and there might be several code changes in different files that
are addressing a same vulnerability. Simple source code analysis technique might not be sufficient
to find the relationship between code changes in different files.

\begin{figure}[H]
  \centering
  \includegraphics[width=.85\linewidth]{images/code_diff.png}
  \caption{Example of code changes to prevent SQL injection \cite{code_diff}}
  \label{figure:code_diff}
\end{figure}

\section{Testing}
This section covers a brief overview of the testing stage. It will be necessary to consider some of
the self-created test cases and scenarios in advance to find all possible bugs and flaws.

\subsection{Unit Testing}
Python provides a unit testing framework as part of its standard library, known as unittest
\cite{unittest}, which offers a complete set of functions suffice to cover the unit testing of this
project. Fundamental test cases include checking the functions for an expected result. Additional
test cases are based on the functionality of the tool to cover every feature implemented.

\begin{table}[H]
	\begin{center}
    \begin{tabular}{|c|c|c|c|c|}
      \hline
      \rowcolor[HTML]{D8D8D8}
      \begin{tabular}[c]{@{}c@{}}Test \\ Case \#\end{tabular} & Test Data & Expected Result & Actual
      Result & Status \\ \hline
       &  &  &  &  \\ \hline
      \end{tabular}
		\caption{Documentation format of the unit testing} \label{table:unittest}
	\end{center}
\end{table}

\subsection{System Testing}
After completing the unit testing, the mining tool has to be tested for its functional requirements,
as mentioned in \hyperref[table:func_req]{\textbf{Table 3.1}}. It is expected that the program would
not be able to handle complicated errors during the early implementation, and the project schedule
would become an iterative process between implementation and testing. It is assumed that the testing
stage would be the most time-consuming process in the whole project, thus it might be required to
allocate more time and effort into this stage.

\section{Evaluation}
This section briefly discusses the approach to evaluate the mining tool on the real world projects
to ensure that the requirements and criteria listed are practical and feasible.

\subsection{Real-world Projects Evaluation} \label{sec:realworld}
Real-world projects generally contain noise in their data due to inconsistency, incompleteness, and
ambiguity \cite{alqahtani_2016}, as shown in \hyperref[figure:comparion_vfc]{\textbf{Figure 2.1}}
and discussed in \hyperref[subsec:finding_vuln]{\textbf{Section 2.4.3}}. Evaluating the mining tool
on several real-world projects will test its ability of handling the noisy data. For the mining tool
to be beneficial to the public, it must be able to produce results with a certain standard. This
could be validated by verifying the accuracy and relevance of the results. It is presumed that the
mining tool would only be suitable for a small set of repositories, and it might require
comprehensive experiments of different configurations to achieve the best result.

Real-world projects including the Linux kernel \cite{linux_repo}, Apache HTTP Server
\cite{apache_httpd_repo}, Apache Tomcat \cite{apache_tomcat_repo}, GitLab Community Edition
\cite{gitlab_repo}, Homebrew core \cite{homebrew_core_repo}, Nixpkgs \cite{nix_packages_repo} and
Odoo \cite{odoo_repo} are a good starting point for this project as they all have a large number of
commits. This approach is reasoable as larger repositories are more likely to contain vulnerability-
fixing commits and have a higher standard or informative commit messages.

\subsection{Quality Evaluation}
Having completed the testing stage does not infer that the repository mining tool would be practical
in a real-world usage. To ensure the feasibility of this project, the tool has to be assessed by
defining and measuring the quality metrics listed below:

\begin{itemize}
	\item \textbf{Relevance}: The measurement of the number of relevant commits retrieved when given a
  regular expression that represent the commit message pattern of a vulnerability.
  \item \textbf{Efficiency}: The total time taken required for the tool to complete the seaching
  process.
\end{itemize}

\section{Ethical Issues}
In this project, it has to be clearly declared that any known or unknown vulnerabilities found by
the mining tool in any repositories will not be publicly disclosed without the permission of the
original authors. The reason is that publishing the vulnerabilities publicly would make the
softwares highly vulnerable to attackers \cite{arora_2010}, and it is recommended to wait for the
official announcement from the software vendors.

\chapter{Design}

\chapter{Implementation and Testing}

\chapter{Results and Discussion}

\chapter{Conclusion}

\printbibliography[heading=bibintoc]

\end{document}