\documentclass[12pt, a4paper]{report}
\edef\restoreparindent{\parindent=\the\parindent\relax}
\usepackage[UKenglish]{babel}
\usepackage[bibstyle=ieee, dashed=false, sorting=nty]{biblatex}
\usepackage[labelfont=bf]{caption}
\usepackage{colortbl}
\usepackage{csquotes}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage[bottom]{footmisc}
\usepackage{graphicx}
\usepackage[hidelinks]{hyperref}
\usepackage{microtype}
\usepackage{parskip}
\usepackage{pgfgantt}

\linespread{1.2}
\restoreparindent

\pagestyle{fancy}
\fancyhf{}
\fancyhead[C]{\leftmark}
\fancyfoot[C]{\thepage}

\addbibresource{references.bib}

\begin{document}
\begin{titlepage}
	\centering
	\includegraphics[width=10cm]{tuos_logo}\par\vspace{1cm}
	\vspace{1cm}

	{\huge\bfseries Finding Security Issues in (Open Source) Software Repositories\par}
	\vspace{1cm}

	{\Large Zer Jun Eng\par}
	\vspace{1cm}

	supervised by\par Dr.~Achim \textsc{Brucker}
	\vfill

	{This report is submitted in partial fulfilment of the requirement for the degree of MEng Software
		Enginnering by Zer Jun Eng}
	\vfill

	{\large COM3610}
	\vfill

	{\large \today}
\end{titlepage}

\pagenumbering{roman}

\chapter*{Declaration}
All sentences or passages quoted in this report from other people's work have been specifically
acknowledged by clear cross-referencing to author, work and page(s). Any illustrations that are not
the work of the author of this report have been used with the explicit permission of the originator
and are specifically acknowledged. I understand that failure to do this amounts to plagiarism and
will be considered grounds for failure in this project and the degree examination as a whole.
\vspace{2cm}

\noindent \begin{tabular}{llp{4.5cm}}
	Name & : & Zer Jun Eng \\ \cline{3-3}
	\\ [-0.5em]
	Date & : & \today      \\ \cline{3-3}
\end{tabular}

\newpage

\chapter*{Abstract}
Each time a vulnerability is identified in a Free/Libre and Open Source Software (FLOSS) project,
the developers will start the fixing process and publish several commits to address the
vulnerability. Some FLOSS projects are also used as a component in both proprietary and open source
softwares. The purpose of this project is to develop a repository mining tool that is able to detect
commits that fix both known and unknown vulnerabilities. From the identified commits, the tool can
determine whether an application is using a vulnerable component.

To achieve better correctness on the results, the tool can be extended to evaluate the lines of code
changed between code commits to identify the real vulnerability-fixing commits. \textit{Results
obtained will be summarised here in the final dissertation}

\chapter*{Acknowledgements}
I would like to thank my parents for their unconditional love and the full financial support
throughout my university life. It would not be possible for me to finish this project and my course
without them.

I would also like to thank my supervisor, Dr. Achim Brucker for continuously providing constructive
advice for my project. I am honoured to work with you, and I look forward to working with you in the
future.

\newpage

\tableofcontents

% \listoffigures

\listoftables

\newpage

\pagenumbering{arabic}

\chapter{Introduction}
\section{Background}
Free/Libre and Open Source Software (\textbf{FLOSS}) is a type of software whose license allows the
users to inspect, use, modify and redistribute the software's source code \cite{crowston_2012}.
Since the introduction of the version control system, many repository hosting sites such as
SourceForge \cite{sourceforge}, Google Code \cite{google_code}, and GitHub \cite{github} have been
launched. As a result, the participation of global communities into FLOSS projects have started to
grow and different contributions were made to improve the softwares quality, which included fixing
software vulnerabilities \cite{dabbish_2012}.

Building a secure software is expensive, difficult, and time-consuming. It is necessary to know when
and how a security vulnerability is fixed throughout the software lifecycle. Software components
such as plugins and application processing interfaces (\textbf{APIs}) are usually developed by
third-party developers and widely reused in both open source and closed source softwares
\cite{khan_2001}. An important factor of the software security is determined by the
information provided by the vendor of the software components for deciding whether to perform
the security update. Hence, the users of software components are advised to check the National
Vulnerability Database (\textbf{NVD}) \cite{nvd} regularly for detailed information of the
vulnerabilities identified in the software components used. Furthermore, it would be more helpful if
the developers of the software components clearly record the list of changes or provide informative
Git commit messages for every version update of their component.

To perform a risk assessment of a potentially vulnerable component, it is required to have a deep
understanding of the vulnerable methods. This information is often described explicitly in the
vulnerability report such as the NVD and the CVE. Therefore, identifying the vulnerability-fixing
commits is a great approach of locating the vulnerable lines of code, which allows checking if a
vulnerable component is being used or not. However, some developers believe that public disclosure
of security vulnerabilities patch is dangerous, thus vulnerability-fixing commits are not commonly
identified and recorded specifically in some open source software repositories to prevent malicious
exploits \cite{arora_2005}. As a result, there is a practical difficulty in applying this analysis
approach to find the security relevant commits that are not documented using CVE or a similar
format, which are known as the silent patches.

To address these issues, a repository mining tool that investigates commit messages and identifies
vulnerable software components can be developed to reduce the time and cost required to mitigate the
vulnerabilities. The repository mining tool should be able to detect the silent patches through an
advanced process, which the tool must analyse the source code changes between commits to locate the
vulnerable lines of code. Moreover, the mining tool should be applicable to all types of software
projects that are using Git as their version control system. Projects that are using a different
version control system are also supported after they have been migrated to Git.

\section{Objectives} \label{sec:objectives}
\begin{itemize}
	\item Identify the security patterns of the most popular security issues in OWASP Top Ten Project.
	The patterns should be expressed using regular expressions.
	\item Develop a repository mining tool to search through the commit history of a repository and
	find a list of commit messages that match the patterns. The list should be produced in a suitable
	file format such as JSON, XML, or CSV.
	\item Extend the mining tool which checks the code difference in the commits found to obtain the
	actual commits fixing the security vulnerabilities. This extension should separate from the mining
	process to make the mining results easier to verify and debug.
\end{itemize}

\section{Challenges} \label{sec:challenges}
This section is a brief summary of the main challenges that might occurred during the project. A
more thorough analysis of the problems and constraints is carried out in
\hyperref[sec:problems_and_constraints]{\textbf{Section 3.5}}.

\begin{itemize}
	\item \textbf{Data}: There are a large number of open source repositories available on GitHub.
	However, it is challenging to find a set of sample repositories that can produce accurate and
	consistent results.
	\item \textbf{Misclassification}: The commit messages for the same vulnerability patch are not
	always the same, thus misclassification is inevitable. Using regular expressions to match the
	patterns in the mining process do not guarantee the correctness of the result.
	\item \textbf{Evaluation}: After mining a list of commits that contain the identified patterns in
	its message, the evaluation process might not correctly locate the lines of code that addressed
	the security vulnerability. It might be required to perform a manual evaluation to correctly
	identify some of the results.
	\item \textbf{Time}: Large repository such as Linux which has more than 780,000 commits in total
	\cite{linux_repo} could be extremely time-consuming for the repository mining tool to complete the
	search and evaluation process.
\end{itemize}

\section{Report Structure}
\textbf{Chapter 2} reviews a range of academic articles, theories, and previous studies that is
related to this project, as well as investigating the techniques and tools to be used.

\noindent\textbf{Chapter 3} is a list of detailed requirements and a thorough analysis of design,
implementation and testing stage. Some core decisions are reviewed in the analysis part to ensure
the feasibility of the project.

\noindent\textbf{Chapter 4} is a comparison between different design concepts, where the advantages
and disadvantages of different approaches are stated. The chosen design is justified with suitable
diagrams provided including wireframes and UML component diagrams.

\noindent\textbf{Chapter 5} describes the implementation process by highlighting novel aspects to
the algorithms used. Testing is performed by following a suitable model to evaluate the
implementation.

\noindent\textbf{Chapter 6} presents all the results along with critical discussions about the main
findings,	and outlines the possible improvements that could be made in the future work.

\noindent\textbf{Chapter 7} summarises the main points of previous chapters and emphasise the
results found.

\section{Relationship to Degree Programme}
This project focuses on the research of real-world software security problems and offers valuable
insights into computer security. By studying the patterns of security vulnerabilities patch in open
source repositories, the practical knowledge for building and ensuring a secure system could be
gained. Moreover, the difficulty of improving software security could be experienced during the
evaluation process in this project. This relates to the Software Engineering degree as it requires a
good understanding in version control system and it aims to improve softwares quality by reducing
the time and effort needed to find security vulnerabilities in the source code.

\chapter{Literature Review}
This chapter will start with the background contents of the project, and then focus on discussing
the security aspect of open source softwares. Additionally, previous and existing relevant works are
reviewed and a critical analysis is provided for the comparison of these resources and this project.

\section{Open Source Security}
The security of open source softwares mostly rely on the collaboration of the community. It is
deduced that the power of open data and crowdsourcing will make open source security more reliable
\cite{hoepman_2007, witten_2001}, and provides more flexibility and freedom over the security option
to their users \cite{payne_2002}. However, when it comes to publishing the vulnerability
information, it is suggested that the list of unconfirmed vulnerabilities should not be published
publicly to protect the users from potential harms \cite{schryen_2011}.

Arora, Nandkumar and Telang \cite{arora_2006} have shown that vulnerabilities that are either secret
or published but not patched attract fewer attacks than patched vulnerabilities. Although the
research was conducted in 2006 and the results might be outdated, it still implies that developers
might include a silent patch into some of the commits that is not explicitly recorded in the commit
messages. It might be a rational approach for not disclosing the work attempted to fix a
vulnerability, but other developers might not be informed of the content change. Furthermore, if a
similar vulnerability is discovered in the future, developers would need more effort for finding the
previous solution. Therefore, it would be very useful for the developers if the mining tool
developed in this project could detect the silent patches.

\section{Taxonomy of Software Vulnerabilities}
There are many software vulnerabilities being identified each year. By using a common vulnerability
identifier system, vulnerability data can be shared across separate vulnerability databases to
facilitate the interoperability of different tools. As this project focuses on finding security
issues in open source repositories, it is necessary to discuss the industry-endorsed standard of
software vulnerabilities categorisation.

\subsection{Common Weakness Enumeration}
The Common Weakness Enumeration (\textbf{CWE}) is a project launched by the Mitre Corporation and
sponsored by the National Cyber Security Division of the United States Department of Homeland
Security \cite{cwe}. The CWE project organises the software weaknesses into a list of different
categories, known as the CWE list. Software weaknesses are defined as errors that can lead to
software vulnerabilities, which includes buffer overflows, authentication errors, code injection,
etc. \cite{cwe_faq}. The CWE is now a formal standard for representing software weaknesses. Each
entry in the CWE list contains detailed information about the specific weakness and is identified by
a unique ID number.

\subsection{Common Vulnerabilities and Exposures}
The Common Vulnerabilities and Exposures (\textbf{CVE}) is another security project launched by the
Mitre Corporation \cite{cve} to provide the community with a complete list of publicly known
security vulnerabilities, known as the CVE entries. Each CVE entry is defined by an ID number, and
includes a description followed by any relevant resources about the vulnerability. It is now the
standardised solution and industry-recognised standard for identifying vulnerabilities and
exposures. However, developers and vendors are not required to publish security vulnerabilities of
their projects in CVE format. They are allowed to use their own naming scheme for the
vulnerabilities, even if the same vulnerability has already been recorded in the CVE list.

\section{Security Issues in Open Source Softwares}
The Open Web Application Security Project (\textbf{OWASP}) is a worldwide non-profit organization
committed to improve and raise the awareness of software security \cite{owasp_home}. The project
members of OWASP have worked together to produce a list of the most critical web application
security risks based on the community feedback and comprehensive data contributed by different
organizations. The list consists of ten categories of security attacks which are considered to be
the most dangerous and popular in recent years. In OWASP Top Ten 2017 \cite{owasp_top10}, one of the
vulnerabilities that is closely related to this project is \textit{Using Components with Known
Vulnerabilities}, which will be extensively discussed.

\subsection{Using Components with Known Vulnerabilities} \label{subsec:components}
It has been indicated that a small software component could create a large error in a software
system \cite{basili_1984, munson_1992, selby_1988}. Components such as plugins, libraries, and
modules are ubiquitous in both open source and proprietary softwares. Third-party components are
increasingly being integrated into softwares to reduce the amount of time and effort required for
development \cite{balzarotti_2006}, but they also increase the risk of vulnerabilities being
introduced into the softwares. These components are mostly maintained by different developers or
organisations, and the time required to fix a vulnerability varies between developers. While the
majority of third-party components are still being actively maintained after a long time, some of
them might have depreciated and security patches are no longer being released. The users might
continue to use a depreciated component if they could not find a better alternative. However, using
outdated components greatly increase the risk of software exploits. Therefore, for any large-scale
system, the developers must scan for vulnerabilities regularly and subscribe to the security news
related to the components used to reduce the risk of security vulnerabilities being introduced into
the system.

Vulnerable components can be found using methods ranging from dependency checking to machine
learning. While this project is related to the former approach, the latter approach concentrates on
finding the relationship between software errors and vulnerabilities to identify or predict
high-risk components. Dependency checking is an approach of detecting dependencies (plugins,
libraries, etc.) with known vulnerabilities in a software. Several open source tools including OWASP
Dependency Check \cite{owasp_dependency}, Retire.js \cite{retirejs}, and Safety \cite{safety} are
applications that identifies vulnerable dependencies in a software project. Cadariu et al.
\cite{cadariu_2015} have used the OWASP Dependency Check tool to find all known vulnerabilities that
have a unique CVE identifier in proprietary softwares written in Java. According to their study, the
OWASP Dependency Check tool has low precision due to the high false positives rate in the large data
sets. However, Cadariu et al. justified that the tool is still usable by taking into account that
the checking process is automated and any security issue found is considered a valuable information
for the users.

Machine learning-based approaches are also applicable to find vulnerable components in a software
system. Briand, Basili and Hetmanski \cite{briand_1993} have developed a model with Optimised Set
Reduction (OSR) algorithm that uses set theory, predicate logic, probability, and vector in the
calculation. The model focused on identifying the components that are more likely to produce a large
number of errors and it was proved to be effective, but the main drawbacks are the complexity of the
implementation and the extensive calculations required. In comparison to Briand's approach,
Scandariato et al. \cite{scandariato_2014} have built a model that uses text mining techniques to
predict vulnerable components. While Briand's model is capable of identifying high-risk components,
Scandariato's model is able to predict vulnerabilities in the future releases of a software
components, and the results achieved are satisfactory.

As a conclusion, static dependency checking tools provide a fast and easy way to scan for vulnerable
components, but the users are required to verify the validity and compatibility of the Results with
their softwares. In contrast, models that use machine learning technique has been proved to be
effective and are more likely to produce consistent and accurate results. However, such models
require a large amount of training data and are only designed for a specific area. While dependency
checking approach is more related to the scope of this project, the capability of predicting
vulnerable software components through machine learning is a great way of preventing severe software
errors. In future work, machine learning could be incorporated into the tool developed in this
project to improve its overall effectiveness.

\section{Mining Software Repositories}
Mining Software Repositories (\textbf{MSR}) is a process of collecting and analysing data from
repositories, which includes version control repositories, mailing list repositories, and bug
tracking repositories. MSR applies to a wide range of fields such as business, research, and
security \cite{poncin_2011}. The purpose of MSR is to extract practical information from rich
metadata and discover hidden trends about a specific evolutionary characteristic \cite{kagdi_2007}.
The information collected could be used in various development process. For example, some developers
could gain insight by mining repositories, which may help them to enhance their software quality
based on previous implementation evidence of other developers \cite{hassan_2008}. While MSR have
various usages in different areas, the primary objective of this project will be focusing on finding
the security issues in open source software repositories through MSR.

In order to identify both hidden and publicly disclosed patches, it is required to make effective
use of MSR technique. A MSR process is normally carried out using tools or scripts made by the
researchers themselves. Although there are many types of research in the MSR field in recent years,
the majority of the tools or scrips used are not published publicly \cite{robles_2010}. As a result,
it is not possible to fully replicate the previous research methods and make improvements based on
that. Despite the undisclosed information of research methods in many papers, Shang
\cite{shang_2009} suggested that the MSR process should be split into several stages, with each
stage focusing on a specific topic of the problem to achieve the optimal efficiency.

\subsection{Keywords Search}
As regular expressions are used in this project to find the vulnerability related commits, it is
required to know the fundamental knowledge of keywords searching techniques. For many complex
approaches, the searching process is considered to be the fundamental step. If the initial results
produced in the searching stage is good, a huge amount of effort could be reduced in the later
stages. However, the prerequisite is that the repository must have a sufficient amount of valuable
information, which can be estimated by judging the history of the repository. To correctly and
precisely retrieve the information for a query, it is required to integrate some algorithms and
modules into the search function. Matsushita, Sasaki, and Inoue \cite{matsushita_2005} developed a
repository search system that makes use of two functions: lexical analysis function and token
comparing function. The system produced very detailed results by deploying recursive search strategy
using the keywords found into every commit. On the contrary, Mockus and Votta \cite{mockus_2000}
designed an automated program that makes use of normalisation, word frequency analysis, and keyword
clustering techniques to search the commit messages. Although the program is able to retrieve the
results that include the keywords, the algorithm is unable to identify similar terms or inconsistent
form of wording for the commit messages.

\subsection{Properties of Vulnerability-Fixing Commits}
For every vulnerability identified in a repository, the vulnerability-fixing process that involves
analysis, implementation, testing, and release will be executed \cite{othmane_2015}. Most of the
vulnerability-fixing commits are pushed during the implementation and testing stage of the process.
However, if the commit message of a fixing commit is ambiguous, it will be challenging for any
repository mining tool to determine the correctness of the commit. By recognising the properties of
vulnerability-fixing commits, it will ease the implementation of the repository mining tool and
enhance the quality of the regular expressions used.

Meneely et al. \cite{meneely_2013} conducted a research to study the properties of commits that
introduce vulnerabilities, in which a reverse approach was used that finds
vulnerability-contributing commit by backtracking from the vulnerability-fixing commits. Meneely et
al. identified the vulnerability-fixing commits by investigating into each vulnerability manually to
find the respective fixing commit. However, Meneely et al. did not explicitly record the process of
identifying vulnerability-fixing commit, thus no constructive information about the properties or
patterns of vulnerability-fixing commits is provided.



\subsection{Finding Vulnerabilities}
Cowan \cite{cowan_2003} suggested a list of software auditing and vulnerability mitigation tools
that perform static code and runtime analysis to find bugs and vulnerabilities. This approach is
popular because it is able to find simple bugs in a short amount of time. However, Bessey et al.
\cite{bessey_2010} claimed that static tools have a negative effect on technical development due to
its high false positives nature. While this statement might be true, it does not imply that all
static tools are not effective as they differ in the techniques used in finding vulnerabilities
\cite{moser_2008}. It might require several experiments of different configurations to obtain the
best result, and the result may vary across different data sets.

This project extends prior work on Reis and Abreu's \cite{secbench} Secbench Mining Tool. The tool
aims to find vulnerabilities patch in GitHub repositories by using specific regular expressions for
each vulnerability pattern. Then it creates a test case for every vulnerability found and these test
cases are evaluated manually. Reis and Abreu \cite{reis_2017} discussed the procedure of the
evaluation and explained that human errors could occur due to source code complexity and similarity
of vulnerability pattern. The approach of Secbench Mining Tool is similar to the concept of this
project. However, it is not practical to perform manual evaluation on every result. In this project,
the tool developed should be able to automate the evaluation process to some extent, while
preserving the accuracy of the results.

\section{Usage of the repository mining tool in other areas}
While the repository mining tool developed in this project is only capable of finding security
issues through Git commits, it can be extended or modified to aid the researches in other areas.
Some examples are briefly discussed in the subsections below.

\subsection{Bugs Finding Model}
Both Williams and Hollingsworth \cite{williams_2005} and Ostrand and Weyuker \cite{ostrand_2004}
utilised MSR technique in their bugs finding model. Williams and Hollingsworth mined the code
changes in each commit to find possible bugs, while Ostrand and Weyuker mined the most frequently
modified files between version releases to predict the bugs-prone files.

\subsection{Machine Learning Model for Automated Vulnerability Detection}
In comparison to the static approach used in the mining tool, machine learning technique could be
introduced to achieve higher reliability and accuracy on the result. Nguyen and Tran
\cite{nguyen_2010} and Perl et al. \cite{perl_2015} have built their machine learning model with
dependency graph and vulnerability-contributing commit as their main approach respectively, while Li
et al. \cite{li_2016} and Russell et al. \cite{russell_2018} used source code analysis method in
their machine learning model. According to their researches, machine learning models are able to
produce relatively high accuracy results.

\chapter{Requirements and Analysis}
The purpose of this chapter is to express the aims in details and discuss the problems to be solved.
This chapter will outline the requirements of the project and list the criteria to be met. The
analysis part will cover every aspect of the design, implementation, and testing stage to ensure
that the project is feasible.

\section{Project Objectives}
Initially, the objectives set in \hyperref[sec:objectives]{\textbf{Section 1.2}} are an ideal
concept of this project. Having completed the background research and literature review, it is now
possible to provide a detailed description and more clearly defined objectives that improve the
feasibility of this project.

\begin{enumerate}
	\item \textbf{Vulnerability patterns}: The term `vulnerability pattern' is used to represent the
  commit message pattern of different vulnerabilities. Correctly identifying the regular expression
  of each vulnerability pattern is time-consuming, and it would also need considerable refinement
  throughout the whole project. Hence, it might be more appropriate to reuse and improve the
  patterns provided in previous related works.
	\item \textbf{Mining the commits}: This task involves creating a repository mining tool that makes
	extensive use of the pre-defined regular expressions to search for the relevant commits. It is
	necessary to consider how closely a commit needs to match with the patterns for it to be included
	in the result. The file format for storing the results is JSON, and reasons are justified in \hyperref[subsec:file_format]{\textbf{Section 3.3.3}}.
	\item \textbf{Evaluating the mined commits}: The mining tool can be extended to include a separate
	function that evaluates the commits mined to find the actual code commit addressing the security
	vulnerabilities. This project will consider to automate the evaluation process to some extent
	while maintaining the accuracy of the results at the standard level.
\end{enumerate}

\section{Software Requirements}
\subsection{Functional Requirements}
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|p{10.3cm}|c|}
			\hline
			\rowcolor[HTML]{D8D8D8}
			\multicolumn{1}{|c|}{Criteria} & Importance \\ \hline
			\textbf{Compatibility}: The mining tool should be able to run on all machines that meet the
			system requirements. & Essential \\ \hline
			\textbf{Completeness}: The mining tool should be able to find all relevant commits of security
			vulnerabilities based on the regular expressions. & Essential \\ \hline
			\textbf{Repeatable}: The results should be repeatable and reproducible. & Essential \\ \hline
			\textbf{Robustness}: The mining tool should be able to handle all possible errors without
			terminating the mining process. & Essential \\ \hline
			\textbf{Scalability}: The mining tool should be able to work on different project sizes,
			provided that the repository contains a certain amount of information. & Essential \\ \hline
			\textbf{Automated Evaluation}: The process of classifying and evaluating the commits into
			different vulnerabilities patch should be automated to a certain extent. & Desirable \\ \hline
			\end{tabular}
		\captionof{table}{Functional requirements of the mining tool} \label{table:func_req}
	\end{center}
\end{table}

\subsection{Non-functional Requirements}
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|p{10.3cm}|c|}
			\hline
			\rowcolor[HTML]{D8D8D8}
			\multicolumn{1}{|c|}{Criteria} & Importance \\ \hline
			\textbf{Code Style}: The source code should be well-commented and follow a consistent coding
      style. & Essential \\ \hline
      \textbf{Documentation}: Installation and user manual should be provided. & Essential \\ \hline
      \textbf{Lightweight}: The mining tool should have minimal dependencies. & Essential \\ \hline
      \textbf{Open source}: As the mining tool is built for researching open source repositories, it
      should be open source to suit the use cases. & Essential \\
      \hline
			\end{tabular}
		\captionof{table}{Non-functional requirements of the mining tool} \label{table:nonfunc_req}
	\end{center}
\end{table}

\section{Analysis}
The aim of this section is to contemplate the options available for this project and review some of
the fundamental decisions to be made before the implementation.

\subsection{Programming Language}
Python 3 \cite{python} is chosen to be the main programming language for the repository mining tool.
While other programming languages may be more suitable for tackling specific problems of this
project, Python 3 provides sufficient coverage over every aspect with its comprehensive
functionality. The greatest advantage of Python 3 is that it has a wide range of libraries that
facilitate the development environment, which fully justified that a complete working solution can
be produced using Python 3.

\subsection{Libraries and Tools}
Since the mining tool is decided to be programmed in Python 3, a wide range of libraries could be
integrated to enhance its functionality.
\begin{itemize}
	\item PyGithub is a Python library build to access the GitHub API \cite{pygithub}.
	\item GitPython is a Python library build to interact with Git repositories using a combination of
	python and git command implementation \cite{gitpython}.
\end{itemize}

\subsection{File Format of Result} \label{subsec:file_format}
The JavaScript Object Notation (\textbf{JSON}) \cite{json} has been chosen as the file format for
storing the results in this project. This is because JSON is supported in Python and it does not
require complicated operations in Python to access the data. While various alternative data
interchange formats such as the Extensible Markup Language (\textbf{XML}) \cite{xml} has its unique
advantages, it is important to choose a data interchange format that consumes less resource and have
lower processing time for a large amount of data. Since it has been proved that JSON has better
performance than XML in terms of processing time and resource utilisation \cite{nurseitov_2009}, it
is considered that JSON would be the best option for this project.

\section{Proposed Method}
This project strongly emphasises the need for finding security issues in open source repositories by
mining software repositories. While it might be impossible to discover the security patches in a
repository through a single search, the problem could be solved using divide and conquer. The ideal
concept of this project is to build a command-line interface program that is able to run two
separate processes: the \textbf{mining} process and the \textbf{evaluation} process. The
\textbf{mining} process takes a Git repository as input, searches through the commit log, and stores
the list of commits that might potentially contain a patch in a JSON file. The \textbf{evaluation}
process takes a JSON file as input, and check the code difference of every commit in the log file to
identify the real patches.

\section{Problems and Constraints} \label{sec:problems_and_constraints}
As mentioned in \hyperref[sec:challenges]{\textbf{Section 1.3}}, the main challenges of this project
are \textbf{data}, \textbf{misclassification}, \textbf{evaluation} and \textbf{time}. The subsequent
challenge is the implementation difficulties, which the severity is dependent on the complexity of
the problems and the resources available. It is also expected that some problems might not be solved
and new problems could emerge in the course of the project. This section will discuss the problems
in detail and review several ways of mitigating them, as well as analysing the possible constraints
that might affect the progress of the project.

Although there are a lot of open source repositories available online, the majority of them does not
have a formal guideline for the documenting the changes in the commit messages. As part of the
\textbf{data} problem, the commit messages in the real-world repositories
(\hyperref[sec:realworld]{\textbf{Section 3.7.1}}) might have lower quality compared to a
self-created repository. It has been reported that the terms \textit{fix}, \textit{add}, and
\textit{test} have the top average term frequency in the commit messages \cite{alali_2008}. With
these indistinct terms being widely used in the commit messages, the performance of the tool may
drop on real-world repository test sets and it would require extra effort for finding the relevant
vulnerability-fixing commits.

There are several ways of mitigating the problems to reduce the risk, provided that the problems are
clearly identified and they are under the project scope. It is estimated that the
\textbf{evaluation} process would be the biggest challenge of this project since it was regarded as
a complicated and difficult area in previous researches. Moreover, this project plans to implement
an automated version of the evaluation process, which will further increase the difficulty level.
The implementation of automated evaluation is hard and it does not guarantee to provide a good
result. It is also extremely challenging for the mining tool to work across repositories programmed
in different programming languages. The constraint is that the tool has to be exhaustively tested to
find the optimal threshold value and for it to be automated and produce good results. Although the
tool might produce good results on some repositories, it does not indicate that the tool will
produce consistent results on all repositories. To ensure the minimum quality of the results, one of
the solutions might be using both automated method for basic filtering and a manual method for
advance refinement.

\section{Testing}
This section covers a brief overview of the testing stage. It will be necessary to consider some of
the self-created test cases and scenarios in advance to find all possible bugs and flaws.

\subsection{Unit Testing}
Python provides a unit testing framework as part of its standard library, known as unittest
\cite{unittest}, which offers a complete set of functions suffice to cover the unit testing of this
project. Fundamental test cases include checking the functions for an expected result. Additional
test cases are based on the functionality of the tool to cover every feature implemented.

\begin{table}[H]
	\begin{center}
    \begin{tabular}{|c|c|c|c|c|}
      \hline
      \rowcolor[HTML]{D8D8D8}
      \begin{tabular}[c]{@{}c@{}}Test \\ Case \#\end{tabular} & Test Data & Expected Result & Actual
      Result & Status \\ \hline
       &  &  &  &  \\ \hline
      \end{tabular}
		\captionof{table}{Documentation format of the unit testing} \label{table:unittest}
	\end{center}
\end{table}

\subsection{System Testing}
After completing the unit testing, the mining tool has to be tested for its functional requirements,
as mentioned in \hyperref[table:func_req]{\textbf{Table 3.1}}. It is expected that the program would
not be able to handle complicated errors during the early implementation, and the project schedule
would become an iterative process between implementation and testing. It is assumed that the testing
stage would be the most time-consuming process in the whole project, thus it might be required to
allocate more time and effort into this stage.

\section{Evaluation}
This section briefly discusses the approach to evaluate the mining tool on the real world projects
to ensure that the requirements and criteria listed are practical and feasible.

\subsection{Real-world Projects Evaluation} \label{sec:realworld}
Real-world projects generally contain noise in their data due to inconsistency, incompleteness, and
ambiguity. Evaluating the mining tool on several real-world projects will test its ability of
handling noisy data. For the mining tool to be beneficial to the public, it must be able to produce
results with a certain standard. This could be validated by verifying the accuracy and relevance of
the results. It is presumed that the mining tool would only be suitable for a small set of
repositories, and it might require comprehensive experiments of different configurations to achieve
the best result.

Real-world projects including the Linux kernel \cite{linux_repo}, Apache HTTP Server
\cite{apache_httpd_repo}, Apache Tomcat \cite{apache_tomcat_repo}, GitLab Community Edition
\cite{gitlab_repo}, Homebrew core \cite{homebrew_core_repo}, Nixpkgs \cite{nix_packages_repo} and
Odoo \cite{odoo_repo} are a good starting point for this project as they all have a large number of
commits. This approach is reasoable as larger repositories are more likely to contain vulnerability-
fixing commits and have a higher standard or informative commit messages.

\subsection{Quality Evaluation}
Having completed the testing stage does not infer that the repository mining tool would be practical
in a real-world usage. To ensure the feasibility of this project, the tool has to be assessed by
defining and measuring the quality metrics listed below:

\begin{itemize}
	\item \textbf{Relevance}: The measurement of the number of relevant commits retrieved when given a
  regular expression that represent the commit message pattern of a vulnerability.
  \item \textbf{Efficiency}: The total time taken required for the tool to complete the seaching
  process.
\end{itemize}

\section{Ethical Issues}
In this project, it has to be clearly declared that any known or unknown vulnerabilities found by
the mining tool in any repositories will not be publicly disclosed without the permission of the
original authors. The reason is that publishing the vulnerabilities publicly would make the
softwares highly vulnerable to attackers \cite{arora_2010}, and it is recommended to wait for the
official announcement from the software vendors.

\chapter{Conclusions and Project Plan}
\section{Main achievements to date}
\begin{itemize}
  \item Completed Literature Review and Requirements and Analysis to a good quality, but not the best yet
  \item Basic implementation such as mining commit messages and matching regular expressions.
  \item Licensing issue considered.
  \item Several design problems have been identified. For example, Git repositories converted from
  Subversion generally do not have `master' as their main branch name, thus extra command line
  options need to be provided.
\end{itemize}

\section{Plan of Action}
\subsection*{Semester 1 and Christmas Vacation}
\begin{ganttchart}[
		hgrid=true,
		vgrid={draw=none, dotted},
		expand chart=\textwidth
	]{1}{12}
	\gantttitle{Semester 1}{12} \\
	\gantttitlelist{1,...,12}{1} \\
	\ganttbar{Background Reading}{1}{10} \\
	\ganttbar{Introduction}{1}{1} \\
	\ganttbar{Analysis}{1}{1} \\
	\ganttbar{Literature Review}{2}{4} \\
	\ganttbar{Requirements and Analysis}{5}{6} \\
	\ganttbar{Proof reading and amendment}{7}{9} \\
  \ganttbar{Design and Implement}{10}{10} \\
  \ganttbar{Initial prototype implementation}{11}{12}
	\ganttlink{elem2}{elem3}
	\ganttlink{elem3}{elem4}
	\ganttlink{elem4}{elem5}
  \ganttlink{elem5}{elem6}
  \ganttlink{elem6}{elem7}
\end{ganttchart}

\begin{itemize}
	\item \textbf{Week 7}: Starting from this week, discuss with the supervisor weekly about the
	document, also it is best to start the design stage early, and show the prototype to the
  supervisor.
  \item \textbf{Week 11}: If the design stage is started early, then it is hoped to produce the
  initial prototype of the tool before Christmas Vacation.
  \item \textbf{Christmas Vacation}: Regularly work on the implementation of the tool and push the
  commits.
\end{itemize}

\subsection{Semester 2}
\begin{ganttchart}[
	hgrid=true,
	vgrid={draw=none, dotted},
	expand chart=\textwidth
]{1}{12}
\gantttitle{Semester 2}{12} \\
\gantttitlelist{1,...,12}{1} \\
\ganttbar{Design}{1}{1} \\
\ganttbar{Implement prototype}{2}{4} \\
\ganttbar{Testing prototype}{3}{6} \\
\ganttbar{Write dissertation}{7}{9} \\
\ganttbar{Submit project}{10}{10} \\
\ganttbar{Poster session}{11}{11}
\ganttlink{elem0}{elem1}
\ganttlink{elem2}{elem3}
\ganttlink{elem3}{elem4}
\ganttlink{elem4}{elem5}
\end{ganttchart}

\begin{itemize}
	\item \textbf{Week 1}: Finished the design and started implementation during holiday.
	\item \textbf{Week 2}: The implementing and testing stage is a repetitive process. It is very
	likely that the program will run into errors in the testing and had to spend more time fixing it.
\end{itemize}

% \chapter{Design}

% \chapter{Implementation and Testing}

% \chapter{Results and Discussion}

% \chapter{Conclusion}

\printbibliography[heading=bibintoc]

\end{document}